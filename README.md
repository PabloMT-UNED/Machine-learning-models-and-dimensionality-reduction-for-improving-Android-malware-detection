**Machine learning models and dimensionality reduction for improving Android malware detection**

_Previous considerations_

First of all it is necessary to have the Jupyter Notebook package installed to run the programs.

You may need additional libraries, such as sklearn, pandas, numpy and the rest to be imported into the programs.

To run the programs, it is necessary to have the dataset loaded, which is not among the attached data in this repository*.

The folders ./in/dataset_splits and ./in/feature_vectors are essential for such execution. In the case of test mode execution, the folder ./in/feature_vectors_test is required, which is also not in the repository*.

*The dataset is property of the DREBIN project, which gave it disinterestedly to carry out the experiments, but we are not authorized to share this material. To request the dataset, please go to the following link: https://drebin.mlsec.org/

The correct order of execution would be:
* create_folders.sh -> Creates all the directories necessary for the execution of the following programs.
* ./bin/PROG1 - Sample selection and chi2 calculation.ipynb
* ./bin/PROG2 - Train and test of E1 and E2.ipynb
* ./bin/PROG4 - Normalizing metric data.ipynb
* ./bin/PROG3 - Validation.ipynb
	
It may be confusing because of the numbering, but since program 3 does not obtain the results dynamically, it is necessary to run program 4 so that it provides them in its last line.

Once program 3 has been executed, program 4 should be executed again to generate the final list, including all the experiments.

This problem will be corrected in future updates.

The results of the iterations are attached in the file ./out/metricas_finales.xls.

**Limitations**

* As a purely static analysis, it does not have the ability to analyze possible application transformations at runtime, although it is able to anticipate some cases by analyzing obfuscation-related features.
* Due to the difficulty in finding recent malware samples, there is a lack of such samples in the dataset, especially regarding certain specific families. The availability of this information would help improve the robustness and accuracy of the model.
* Another limitation of static analysis is the possibility of mimetic and poisoning attacks. Renaming the activities and components of an application between the training and detection phases can affect discriminative features. On the other hand, it is also possible to bypass the analysis result by adding features that are typical of goodware applications.


**Pre-processing**

The DREBIN dataset does not consist of a simple ".csv" file. Instead, it is distributed in several folders containing the samples of the applications, the characteristics of each app in a ".txt" file and several more folders with the test sets they used in the DREBIN's experiments. A list labeling the samples as malware or goodware is not available, so this information had to be extracted from the test sets manually. All features extracted from the samples, both from the ""manifest.xml" file and from the decompiled application code itself, were used as input data.

According to the initial information, extracted from the DREBIN documentation, the dataset has 123,453 benign and 5,560 malware applications, i.e. a total of 129,013 samples. Combining all the features extracted from the files and removing duplicates gives a total of 545,333 features.

In order to be able to label the samples, a script is developed for relating the applications with the classes to which they belong (malware / goodware), extracting the information from the test set. Once the data had been labeled, we found that there was no information on 67 samples, so we decided to eliminate them from the dataset. Finally, the dataset used in this work is composed of 123,393 goodware samples and 5,553 malware samples (128,946 samples in total). After these adjustments, the total number of features is recalculated to 545,196.

After the above steps, a binary matrix is created for which rows represent applications and columns represent features. This matrix is filled by default to 0, and a 1 is entered if the application X contains the feature in column Y. The hash of the application is used as the application identifier.
