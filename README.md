**Machine learning models and dimensionality reduction for improving Android malware detection**

_Previous considerations_

First of all it is necessary to have the Jupyter Notebook package installed to run the programs.

You may need additional libraries, such as sklearn, pandas, numpy and the rest to be imported into the programs.

To run the programs, it is necessary to have the dataset loaded, which is not among the attached data in this repository*.

The folders ./in/dataset_splits and ./in/feature_vectors are essential for such execution. In the case of test mode execution, the folder ./in/feature_vectors_test is required, which is also not in the repository*.

*The dataset is property of the DREBIN project, which gave it disinterestedly to carry out the experiments, but we are not authorized to share this material. To request the dataset, please go to the following link: https://drebin.mlsec.org/

The correct order of execution would be:
* create_folders.sh -> Creates all the directories necessary for the execution of the following programs.
* ./bin/PROG1 - Sample selection and chi2 calculation.ipynb
* ./bin/PROG2 - Train and test of E1 and E2.ipynb
* ./bin/PROG4 - Normalizing metric data.ipynb
* ./bin/PROG3 - Validation.ipynb
	
It may be confusing because of the numbering, but since program 3 does not obtain the results dynamically, it is necessary to run program 4 so that it provides them in its last line.

Once program 3 has been executed, program 4 should be executed again to generate the final list, including all the experiments.

This problem will be corrected in future updates.

The results of the iterations are attached in the file ./out/metricas_finales.xls.

**Limitations**

* As a purely static analysis, it does not have the capacity to analyse possible application transformations at runtime, although it is able to anticipate some cases by analysing obfuscation-related features.
* It also lacks a larger number of malware samples from some families, in order to create a more robust and accurate model. It is not easy to find recent malware samples.
* Another limitation of static analysis is the possibility of mimetic and poisoning attacks. Renaming the activities and components of an application between the training and detection phase can affect the discriminative features. On the other hand, it is also possible to try to bypass the analysis result by adding features that are typical of goodware applications.


**Pre-processing**

The dataset does not consist of a csv file as such, instead it is distributed in several folders containing the samples of the applications, the characteristics of each app in a ‘.txt’ file and several more folders with the test sets they used in their experiment. There is also no list in which the samples are labelled as malware or goodware, so this information had to be extracted from the test games, in which the label of each sample appears, although they are not all in the same file.

Based on the initial information, extracted from the DREBIN documentation, the dataset has 123,453 benign applications and 5,560 malware, i.e. a total of 129,013 samples. By compiling all the features extracted from the files and removing duplicates, a total of 545,333 features are obtained.

In order to be able to label the samples, a script is developed to be able to relate the applications with the classes to which they belong (malware / goodware), extracting the information from the test set. Once the data had been labelled, we found that there was no information on 67 samples, so we decided to eliminate them from the dataset as we did not know whether they were malware or goodware. Finally, the dataset used in this work is composed of 123,393 goodware samples and 5,553 malware samples (128,946 samples in total), which implies 60 less goodware samples and 7 less malware samples according to the initial DREBIN approach. After these adjustments, the total number of features is recalculated to 545,196.

After the above steps, a matrix is defined, where each dimension is either 0 or 1. In short, a matrix is created in which the rows represent the applications and the columns represent the features. This matrix is filled by default to 0, and a 1 is entered if the application X contains the feature in column Y. The hash of the application is used as the application identifier.
