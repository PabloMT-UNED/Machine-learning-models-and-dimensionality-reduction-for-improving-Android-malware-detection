{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from threading import current_thread, Lock, Thread\n",
    "import queue\n",
    "from multiprocessing import cpu_count\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'figure.max_open_warning': 0}) #evitar warnings por muchos graficos abiertos\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, cohen_kappa_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "import itertools\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "\n",
    "import json\n",
    "\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import shutil\n",
    "import psutil\n",
    "import gc\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diferentes escenarios de ejecución:\n",
    "# - Tipo lab: Indica el modelo de ejecución. En este caso hay 2. 1 para indicar la ejecución en modo resultados binarios,\n",
    "#             en el que solo buscamos si es o no malware. 2: Para indicar la ejecución en modo familias, en las que se\n",
    "#             tratará de etiquetar los resultados por familias de malware (TRABAJO FUTURO)\n",
    "# - Experimento: Cada laboratorio tiene 3 experimentos. 1: Ejecución mediante train/test. 2: Ejecución mediante train/test/validation\n",
    "#                3: Se ejecuta la parte \"validation\" de los mejores resultados obtenidos en el experimento 2.\n",
    "# - Usar features: Cada experimento se ejecuta con 2 particiones del dataset original. Manifest: Solo features recogidas\n",
    "#                  en el fichero manifest de la aplicación. All: Ejecución con todas las features de la aplicación.\n",
    "\n",
    "#################################################################################################################\n",
    "#IMPORTANTE, tal y como se planteó en un principio, las ejecuciones se realizan por experimento y tipo de feature\n",
    "#Por lo que hay que seleccionar en las variables globales el experimento y tipo de dataset\n",
    "#Futura mejora, modificarlo para que sea iterable\n",
    "#################################################################################################################\n",
    "\n",
    "#Variables controles ejecucion\n",
    "calcular_descuadre=0\n",
    "\n",
    "tipo_lab=1 #1 binario / 2 por familias DEJAR EN 1 - El 2 es un inicio de trabajo futuro\n",
    "\n",
    "usar_features='all' #manifest, selection o all\n",
    "experimento=1 #1 train/test - 2 train/test(validation) El 3 se ejecuta en otro programa\n",
    "\n",
    "lista_algoritmos=['RL','RFO','NBA','ARD','SVM']\n",
    "lista_k = [50,500,5000,15000]\n",
    "\n",
    "if experimento < 1 or experimento > 2:\n",
    "    print (\"El experimento solo puede ser 1 o 2. Revise la variable experimento.\")\n",
    "    sys.exit()\n",
    "\n",
    "if usar_features not in ['all','manifest']:\n",
    "    print (\"El tipo de dataset es incorrecto. Solo se pueden utilizar all o manifest. Revise la variable usar features.\")\n",
    "    sys.exit()\n",
    "    \n",
    "#Variable para ejecutar prueba (test=1)\n",
    "test=1\n",
    "\n",
    "#DIRECTORIOS\n",
    "\n",
    "# -----\n",
    "# RUTAS\n",
    "# -----\n",
    "path_bin = os.getcwd()\n",
    "parent_path = Path(path_bin).parent.absolute()\n",
    "\n",
    "#Este programa se desarrollo concatenando los directorios con \\\\, en futuras actualizaciones se corregira, adaptandolo a objetos tipo Path\n",
    "delimiter = \"\\\\\"\n",
    "\n",
    "#Variable HOME\n",
    "if test:\n",
    "    HOME=str(parent_path.joinpath('TEST')) + delimiter\n",
    "    print (HOME)\n",
    "else:\n",
    "    HOME=str(parent_path) + delimiter\n",
    "    print (HOME)\n",
    "    \n",
    "IN=HOME+'in' + delimiter\n",
    "IN_DATA=IN+'data' + delimiter\n",
    "IN_TTV=IN+'TTV' + delimiter\n",
    "IN_CHI=IN+'logs_chi' + delimiter\n",
    "OUT=HOME+'out' + delimiter\n",
    "BIN=HOME+'bin' + delimiter\n",
    "RESULT=HOME+'result' + delimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if test == 1:\n",
    "    dir_features = IN + 'feature_vectors_test'\n",
    "else:\n",
    "    dir_features = IN + 'feature_vectors'\n",
    "\n",
    "\n",
    "dir_malware = IN + 'dataset_splits' + delimiter + 'leave-one-family-out' + delimiter + '10-samples'\n",
    "dir_dict_fam = IN_DATA + 'familias_mw'\n",
    "\n",
    "hora_log=datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "dir_log = OUT + 'logs' + delimiter\n",
    "dir_output = dir_log + 'LOG'+hora_log + delimiter\n",
    "\n",
    "dir_log = dir_output +'log_ejecucion'# + hora_log\n",
    "dir_log_met = dir_output + 'log_metricas'# + hora_log\n",
    "\n",
    "#TO-DO COMPROBAR EXITENCIA DE DIRECTORIOS ESQUELETOS\n",
    "\n",
    "dir_out_mod = OUT + 'models' + delimiter + 'lab'+ str(tipo_lab) + delimiter + 'exp' + str(experimento) + delimiter\n",
    "dir_out_res = OUT + 'results' + delimiter + 'lab'+ str(tipo_lab) + delimiter + 'exp' + str(experimento) + delimiter\n",
    "dir_out_metrics = OUT + 'metrics' + delimiter + 'lab'+ str(tipo_lab) + delimiter + 'exp' + str(experimento) + delimiter\n",
    "file_metrics = dir_out_metrics + 'metrics_'+ usar_features + '_test_' + str(test) + '.json'\n",
    "dir_out_mc = dir_out_metrics + 'mc' + delimiter\n",
    "dir_out_roc = dir_out_metrics + 'rc' + delimiter\n",
    "\n",
    "\n",
    "#BORRAR\n",
    "cont_fich=0\n",
    "\n",
    "#Listas\n",
    "list_dict_features_train=[]\n",
    "list_dict_features_test=[]\n",
    "lista_features=[]\n",
    "lista_sum_features_app=[]\n",
    "\n",
    "features_manifest = ['feature','permission','provider','activity','service_receiver','intent']\n",
    "\n",
    "### Loggin\n",
    "\n",
    "\n",
    "#LOG EJECUCION\n",
    "os.makedirs(dir_output,exist_ok = True)\n",
    "\n",
    "graba_log = logging.getLogger('MyLogger')\n",
    "graba_log.setLevel(logging.DEBUG)\n",
    "handler = logging.FileHandler(dir_log, mode='w')\n",
    "graba_log.addHandler(handler)\n",
    "\n",
    "#LOG METRICAS\n",
    "\n",
    "graba_log_met = logging.getLogger('MyLogger2')\n",
    "graba_log_met.setLevel(logging.DEBUG)\n",
    "handler_met = logging.FileHandler(dir_log_met, mode='w')\n",
    "graba_log_met.addHandler(handler_met)\n",
    "### End loggin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprueba_directorios(*args):\n",
    "    for directorio in args:\n",
    "        #print(directorio)\n",
    "        os.makedirs(directorio,exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mem():\n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem=process.memory_full_info()[1] / float(2 ** 20)\n",
    "    \n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mensajes_log(tipo=None, hora_inicio=None, hora_fin=None, texto=None, k=None, iteracion=None, f_dict=None, nivel=1, simb=\"--\"):\n",
    "    '''tipos:\n",
    "        - INI = Mensaje de inicio de ejecución bloque\n",
    "        - FIN = Mensaje de final de ejecución bloque\n",
    "        - IAL = Inicio algoritmo\n",
    "        - FAL = Final algoritmo\n",
    "        - IME = Inicio Metricas\n",
    "        - FME = Final metricas '''\n",
    "    \n",
    "    ahora=datetime.datetime.now().strftime(\"%Y/%m/%d %H:%M:%S\")\n",
    "    \n",
    "    if tipo == \"INI\":\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" INICIO \" + texto + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" INICIO \" + texto + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "    elif tipo == \"RES\":\n",
    "        tiempo = hora_fin - hora_inicio\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" RESUMEN \" + texto + \": \" + str(tiempo))\n",
    "        print(ahora + \" \" + nivel*simb + \" RESUMEN \" + texto + \": \" + str(tiempo))\n",
    "    elif tipo == \"FIN\":\n",
    "        tiempo = hora_fin - hora_inicio\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" FINAL \" + texto + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" RESUMEN \" + texto + \": \" + str(tiempo))\n",
    "        print(ahora + \" \" + nivel*simb + \" FINAL \" + texto + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" RESUMEN \" + texto + \": \" + str(tiempo))\n",
    "    elif tipo == \"IAL\":\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" INICIO ALGORITMO \" + texto + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" INICIO ALGORITMO \" + texto + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "    elif tipo == \"FAL\":\n",
    "        tiempo = hora_fin - hora_inicio\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" FINAL ALGORITMO \" + texto + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" RESUMEN ALGORITMO \" + texto + \": \" + str(tiempo))\n",
    "        print(ahora + \" \" + nivel*simb + \" FINAL ALGORITMO \" + texto + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" RESUMEN ALGORITMO \" + texto + \": \" + str(tiempo))\n",
    "    elif tipo == \"IME\":\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" INICIO METRICAS ALGORITMO \" + texto + \" con K=\" + str(k) + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" INICIO METRICAS ALGORITMO \" + texto + \" con K=\" + str(k) + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "    elif tipo == \"FME\":\n",
    "        tiempo = hora_fin - hora_inicio\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" FINAL METRICAS ALGORITMO \" + texto + \" con K=\" + str(k) + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" RESUMEN METRICAS ALGORITMO \" + texto + \" con K=\" + str(k) + \": \" + str(tiempo))\n",
    "        print(ahora + \" \" + nivel*simb + \" FINAL METRICAS ALGORITMO \" + texto + \" con K=\" + str(k) + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" RESUMEN METRICAS ALGORITMO \" + texto + \" con K=\" + str(k) + \": \" + str(tiempo))\n",
    "    elif tipo == \"MMC\":\n",
    "        texto_hora=ahora + \" \"\n",
    "        espacios=len(texto_hora)\n",
    "        lineas=texto.split(\"\\n\")\n",
    "        for linea in lineas:\n",
    "            graba_log.debug(espacios*\" \" + nivel*simb + \" \" + linea)\n",
    "    elif tipo == \"IFS\":\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" INICIO FEATURE SELECTION iteracion=\" + str(iteracion) + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" INICIO FEATURE SELECTION iteracion=\" + str(iteracion) + \": \" + hora_inicio.strftime(\"%H:%M:%S\"))\n",
    "    elif tipo == \"FFS\":\n",
    "        tiempo = hora_fin - hora_inicio\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" FIN FEATURE SELECTION iteracion=\" + str(iteracion) + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" RESUMEN FEATURE SELECTION iteracion=\" + str(iteracion) + \": \" + str(tiempo))\n",
    "        print(ahora + \" \" + nivel*simb + \" FIN FEATURE SELECTION iteracion=\" + str(iteracion) + \": \" + hora_fin.strftime(\"%H:%M:%S\"))\n",
    "        print(ahora + \" \" + nivel*simb + \" RESUMEN FEATURE SELECTION iteracion=\" + str(iteracion) + \": \" + str(tiempo))\n",
    "    elif tipo == \"MSG\":\n",
    "        graba_log.debug(ahora + \" \" + nivel*simb + \" \"+ texto)\n",
    "        print(texto)\n",
    "    elif tipo == \"EME\":\n",
    "        graba_log_met.debug(json.dumps(f_dict))\n",
    "        print(json.dumps(f_dict))\n",
    "    else:\n",
    "        graba_log.debug(\"NO se recibe param. tipo correcto. Texto: \" + texto)\n",
    "        print(\"NO se recibe param. tipo correcto. Texto: \" + texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nombres_muestras(dir_features):\n",
    "    lista_ret=[]\n",
    "    orden=0\n",
    "    for nombre in os.listdir(dir_features):\n",
    "        if os.path.isfile(os.path.join(dir_features, nombre)):\n",
    "            lista_ret.append([orden,nombre])\n",
    "            orden+=1\n",
    "            \n",
    "    return lista_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_rellenar_dataset(cola, df_dataset):\n",
    "\n",
    "    # Para evitar la superposición en la impresión de textos.\n",
    "    lock = Lock()\n",
    "    \n",
    "    cores = cpu_count()\n",
    "    threads = []\n",
    "    \n",
    "    for i in range(cores):\n",
    "        \n",
    "        thread = Thread(target=rellenar_dataset, args=(cola, lock, df_dataset))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Terminar hilos.\n",
    "    for i in range(cores):\n",
    "        cola.put(None)\n",
    "\n",
    "    # Esperar a que finalice el procesamiento de cada hilo.\n",
    "    print(\"Waiting for threads...\")\n",
    "    for t in threads:\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_extraer_features(cola, list_dict_features,dir_features):#, lista_features, lista_sum_features_app, calcular_descuadre, usar_features, features_manifest):\n",
    "    \n",
    "    # Para evitar la superposición en la impresión de textos.\n",
    "    lock = Lock()\n",
    "    \n",
    "    cores = cpu_count()\n",
    "    threads = []\n",
    "    \n",
    "    for i in range(cores):\n",
    "\n",
    "        thread = Thread(target=extraer_features, args=(cola, lock, list_dict_features,dir_features))#, lista_features, lista_sum_features_app, calcular_descuadre, usar_features, features_manifest))\n",
    "\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "\n",
    "    # Terminar hilos.\n",
    "    for i in range(cores):\n",
    "        cola.put(None)\n",
    "\n",
    "    # Esperar a que finalice el procesamiento de cada hilo.\n",
    "    print(\"Waiting for threads...\")\n",
    "    for t in threads:\n",
    "        t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar_integridad(df_dataset):\n",
    "    #TRAZA de tiempo\n",
    "    inicio_suma = datetime.datetime.now()\n",
    "    print (\"Inicio Suma: \" + inicio_suma.strftime(\"%H:%M:%S\"))\n",
    "    \n",
    "    df_suma = pd.DataFrame(columns=['suma'])\n",
    "    df_suma['suma'] = df_dataset.sum(axis=1)\n",
    "    df_suma[['o1','app1']]=lista_app\n",
    "    \n",
    "    df_contadores = pd.DataFrame(lista_sum_features_app, columns=['Orden', 'App', 'Suma_lectura'])\n",
    "    \n",
    "    df_suma = pd.merge(left=df_suma,right=df_contadores, how='left', left_on='app1', right_on='App')\n",
    "    \n",
    "    df_suma['resta'] = df_suma[\"suma\"] - df_suma[\"Suma_lectura\"]\n",
    "    \n",
    "    app_descuadradas = df_suma.loc[df_suma.loc[:, 'resta'] > 0].resta.count()\n",
    "    \n",
    "    #TRAZA de tiempo\n",
    "    fin_suma = datetime.datetime.now()\n",
    "    print (\"Fin Suma: \" + fin_suma.strftime(\"%H:%M:%S\"))\n",
    "    print (\"Resumen SUMA: \" + str(fin_suma - inicio_suma))\n",
    "    \n",
    "    return app_descuadradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_codigos_familias(dir_dict_fam):\n",
    "    dict_familias={}\n",
    "    \n",
    "    print (dir_dict_fam)\n",
    "    if os.path.exists(dir_dict_fam):\n",
    "        with open(dir_dict_fam, 'r') as fich:\n",
    "            dict_familias = json.load(fich)\n",
    "                   \n",
    "    return dict_familias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escribir_codigos_familias(dir_dict_fam, dict_familias):\n",
    "    with open(dir_dict_fam, 'w') as file:\n",
    "        json.dump(dict_familias, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_etiquetado(dir_malware, lista_app, tipo_lab, dict_familias_mw):\n",
    "    estado = True\n",
    "    df_app = pd.DataFrame(lista_app, columns=['ORDEN_APP','APP_HASH'])\n",
    "    df_app = df_app.sort_values(['ORDEN_APP'])\n",
    "    \n",
    "    df_muestras = get_muestras_malware(dir_malware)\n",
    "    \n",
    "    df_app = pd.merge(left=df_app,right=df_muestras, how='left', left_on='APP_HASH', right_on='APP_HASH')\n",
    "\n",
    "    df_app['Y_TARGED'] = df_app['FAMILY_MALWARE'].to_list()\n",
    "    \n",
    "    inv_dict_familias_mw= {}\n",
    "    \n",
    "    if tipo_lab == 1:\n",
    "        df_app['Y_TARGED']=df_app['Y_TARGED'].replace(to_replace=\"NO_MW\", value=np.uint8(0))\n",
    "        df_app['Y_TARGED']=df_app['Y_TARGED'].replace(to_replace=\"[A-Za-z]*\", value=np.uint8(1), regex=True).astype(np.uint8)\n",
    "    else:\n",
    "        nueva_familia=False\n",
    "\n",
    "        #Cargamos todos los codigos asignados a las familias y comprobamos si hay distintas en el dataset\n",
    "        dict_familias_mw = get_codigos_familias(dir_dict_fam)\n",
    "        lista_familias_dataset = df_muestras['FAMILY_MALWARE'].drop_duplicates().to_list()\n",
    "\n",
    "        for familia in lista_familias_dataset:\n",
    "            if familia not in dict_familias_mw:\n",
    "                nueva_familia=True\n",
    "                dict_familias_mw.update({familia : len(dict_familias_mw)})\n",
    "\n",
    "        if nueva_familia:\n",
    "            mensajes_log(tipo=\"MSG\", texto=\"ATENCIÓN - Existen nuevas familias de malware no procesadas anteriormente.\")\n",
    "            escribir_codigos_familias(dir_dict_fam, dict_familias_mw)\n",
    "        \n",
    "        #Cargamos los codigos en el dataset. LIMITAMOS EL TAMAÑO A 255 FAMILIAS, uint8 max 256.\n",
    "        if len(dict_familias_mw) > 255:\n",
    "            estado = False\n",
    "        else:\n",
    "            for familia in dict_familias_mw:\n",
    "                df_app['Y_TARGED']=df_app['Y_TARGED'].replace(to_replace=familia, value=np.uint8(dict_familias_mw[familia]))\n",
    "        \n",
    "        #Cargamos el dict_familias_mw inverso      \n",
    "        \n",
    "        for key, val in dict_familias_mw.items():\n",
    "            inv_dict_familias_mw.update({val : key})\n",
    "        \n",
    "        mensajes_log(tipo=\"MSG\", texto=\"Cargado diccionario de familias de malware.\")\n",
    "        \n",
    "    return df_app, estado #, dict_familias_mw, inv_dict_familias_mw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar_existe_fichero(dir_fichero, hora_log, sustituir=1, nivel=1):\n",
    "    #Si existe el fichero, se renombra con \".bk_fecha y hora del backup\".    \n",
    "        \n",
    "    if os.path.exists(dir_fichero):\n",
    "        if sustituir == 1:\n",
    "            ruta_fich=os.path.split(dir_fichero)[0]\n",
    "            nombre_fich=os.path.split(dir_fichero)[1]\n",
    "\n",
    "            extension=\".bk_\" + hora_log\n",
    "            dir_backup=ruta_fich+delimiter+'backup'\n",
    "\n",
    "            nuevo_nombre=nombre_fich+extension\n",
    "            nueva_ruta=dir_fichero+extension\n",
    "\n",
    "            os.rename(dir_fichero, nueva_ruta)\n",
    "\n",
    "            if not os.path.exists(dir_backup):\n",
    "                os.mkdir(dir_backup)\n",
    "\n",
    "            fich_backup = dir_backup +delimiter+ nuevo_nombre\n",
    "\n",
    "            shutil.move(nueva_ruta, dir_backup)\n",
    "\n",
    "            mensajes_log(tipo=\"MSG\", texto=\"Creado backup \" + fich_backup, nivel=nivel)\n",
    "            \n",
    "            return True\n",
    "        else:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para prevenir que varios threads escriban al mismo tiempo por pantalla.\n",
    "def impresion_segura(lock, *args):\n",
    "\n",
    "    lock.acquire()\n",
    "    print(*args)\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rellenar_dataset(cola_features, lock, df_dataset):\n",
    "    \n",
    "    while True:\n",
    "        dict_temp = cola_features.get()\n",
    "        \n",
    "        if dict_temp is not None:\n",
    "            \n",
    "            for feature in dict_temp['features']:\n",
    "\n",
    "                if feature in df_dataset.columns:\n",
    "                    lock.acquire() \n",
    "                    df_dataset.at[dict_temp['orden'], feature] = np.uint8(1)\n",
    "                    lock.release()\n",
    "\n",
    "        if dict_temp is None:\n",
    "            break\n",
    "    #impresion_segura(lock, current_thread().name, \"exited.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_features(cola, lock, list_dict_features, dir_features):#, lista_features, lista_sum_features_app, calcular_descuadre, usar_features, features_manifest):\n",
    "    \n",
    "    while True:\n",
    "        app = cola.get()\n",
    "       \n",
    "        if app is not None:\n",
    "\n",
    "            file_app = dir_features + delimiter + app[1]\n",
    "            \n",
    "            lista_features_app=[] #Guarda todas las features de la app en cada bucle\n",
    "            cont_features=0 #Se utiliza para saber el numero de features añadidas por cada App\n",
    "\n",
    "            try:\n",
    "                with open(file_app, 'r') as f:\n",
    "                    \n",
    "                    if usar_features.strip() == 'manifest':\n",
    "                        for linea in f:\n",
    "                            #Controlamos lineas en blanco\n",
    "                            feature = linea.replace('\\n','').strip()\n",
    "                            \n",
    "                            division = feature.split(\"::\")\n",
    "                            \n",
    "                            if division[0] in features_manifest:\n",
    "\n",
    "                                lista_features_app.append(feature)\n",
    "                        \n",
    "                    else: #Obtener TODAS las features\n",
    "\n",
    "                        for linea in f:\n",
    "                            #Controlamos lineas en blanco\n",
    "                            feature = linea.replace('\\n','').strip()\n",
    "                            if feature.strip() != '':\n",
    "\n",
    "                                lista_features_app.append(feature)\n",
    "\n",
    "\n",
    "            except Exception as e:\n",
    "                print (str(e) + \" --- \" + file_app)\n",
    "            \n",
    "            #Control si se ha activado el modo de control de descuadre de sumatorios\n",
    "            #En caso de activarse, guardamos junto a la app y sus features, el contador de estas.\n",
    "            if calcular_descuadre==1:\n",
    "                lock.acquire()\n",
    "                list_dict_features.append({'orden': app[0], 'app': app[1], 'features': lista_features_app})\n",
    "                lista_sum_features_app.append([app[0], app[1], len(lista_features_app)])\n",
    "                lock.release()\n",
    "            else:\n",
    "                lock.acquire()\n",
    "                list_dict_features.append({'orden': app[0], 'app': app[1], 'features': lista_features_app})\n",
    "                lock.release()\n",
    "\n",
    "        if app is None:\n",
    "            break\n",
    "    #impresion_segura(lock, current_thread().name, \"terminó ejecución.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_muestras_malware(dir_malware):\n",
    "    \n",
    "    df_muestras = pd.DataFrame()\n",
    "    \n",
    "    #Recorre cada carpeta de las pruebas de las 20 familias para extraer todos los regitros\n",
    "    for name in os.listdir(dir_malware):\n",
    "        if os.path.isdir(os.path.join(dir_malware, name)):\n",
    "            dir_nuevo = os.path.join(dir_malware, name)\n",
    "            for nombre_fichero in os.listdir(dir_nuevo):\n",
    "                \n",
    "                if nombre_fichero == \"validate_cs\":\n",
    "                    temp_df = pd.read_csv(os.path.join(dir_nuevo, nombre_fichero), header=None)\n",
    "                    df_muestras = pd.concat([df_muestras, temp_df])\n",
    "                \n",
    "    df_muestras = df_muestras.drop_duplicates()\n",
    "    df_muestras = df_muestras.fillna('NO_MW')\n",
    "    df_muestras.columns=['APP_HASH', 'FAMILY_MALWARE']\n",
    "    \n",
    "    print (\"DF_MUESTRAS: \" + str(df_muestras.shape))\n",
    "    return df_muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_estimada, dir_output, cuerpo_nom_fich, tit_graficos,dir_out_mc, hora_log):\n",
    "    \"\"\"\n",
    "    Esta función imprime y marca la matriz de confusión.\n",
    "    \"\"\"\n",
    "    cmap=plt.cm.Blues\n",
    "    classes = list(Counter(y_test).keys())\n",
    "    cm = confusion_matrix(y_test, y_estimada, labels=classes)\n",
    "    np.set_printoptions(precision=2)\n",
    "    \n",
    "    clasif_repo = classification_report(y_test, y_estimada, zero_division='warn')\n",
    "    mensajes_log(tipo=\"MMC\", texto=clasif_repo, nivel=5,simb=\"  \")\n",
    "    \n",
    "    clasif_repo_dict = classification_report(y_test, y_estimada, zero_division='warn', output_dict=True)\n",
    "\n",
    "    titulo='M.C. ' + tit_graficos\n",
    "    \n",
    "    plt.figure(1)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(titulo)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "        horizontalalignment=\"center\",\n",
    "        color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Etiqueta verdadera')\n",
    "    plt.xlabel('Etiqueta predecida')\n",
    "    \n",
    "    #nombre_fichero = 'MC_' + algoritmo + \"_L\" + str(tipo_lab) + \"_E\" + str(experimento) + \"_k\" + str(k) + \"_i\" + str(iteracion) + \"_\" + datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    nombre_fichero = 'MC_' + cuerpo_nom_fich\n",
    "    \n",
    "    #Guardamos copia en la propia carpeta de log, a modo de backup\n",
    "    ruta_fichero_flog = dir_output + nombre_fichero + \".jpg\"\n",
    "    plt.savefig(ruta_fichero_flog, bbox_inches='tight')\n",
    "    \n",
    "    #Guardamos copia en el directorio de metricas\n",
    "    ruta_fichero_met = dir_out_mc + nombre_fichero + \".jpg\"\n",
    "    existe_f = comprobar_existe_fichero(ruta_fichero_met, hora_log, nivel=5)\n",
    "    plt.savefig(dir_out_mc + nombre_fichero + \".jpg\", bbox_inches='tight')\n",
    "    \n",
    "    plt.close(1)\n",
    "    #LOG y traza\n",
    "    mensajes_log(tipo='MSG', texto=\"impreso grafico MC\" + ruta_fichero_flog, nivel=5)\n",
    "    \n",
    "    return clasif_repo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_metricas_totales(file_metrics, dic_met):\n",
    "\n",
    "    if os.path.exists(file_metrics):\n",
    "    \n",
    "        with open (file_metrics, 'r') as f_metrics:\n",
    "            metrics = json.load(f_metrics)\n",
    "\n",
    "        metrics.append(dic_met)\n",
    "    else:\n",
    "        metrics = [dic_met]\n",
    "    \n",
    "    with open(file_metrics,'w') as new_metrics: \n",
    "        json.dump(metrics, new_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_metricas(t_ejecucion, X_train, X_test, y_train, y_test, y_estimada, test, algoritmo, k, iteracion, dir_output,usar_features,tipo_lab,experimento,hora_log,cuerpo_nom_fich,tit_graficos,dir_out_mc, dir_out_roc):\n",
    "    #LOG y traza\n",
    "    inicio_metrica = datetime.datetime.now()\n",
    "    mensajes_log(tipo='IME', hora_inicio=inicio_metrica, texto=algoritmo, k=k, nivel=5)\n",
    "    \n",
    "    #Calculo roc_auc y su grafica\n",
    "    mensajes_log(tipo='MSG', texto=\"Memoria ANTES ROC: \" + str(get_mem()),nivel=5)\n",
    "    \n",
    "    roc_score = plot_roc_curve(y_test,y_estimada,dir_output,cuerpo_nom_fich,tit_graficos,dir_out_roc,hora_log)\n",
    "    \n",
    "    mensajes_log(tipo='MSG', texto=\"Memoria DESPUES ROC: \" + str(get_mem()),nivel=5)\n",
    "    \n",
    "\n",
    "    #Calculo matriz de confusión y su grafica\n",
    "    mensajes_log(tipo='MSG', texto=\"Memoria ANTES MC: \" + str(get_mem()),nivel=5)\n",
    "    \n",
    "    clasif_repo = plot_confusion_matrix(y_test, y_estimada, dir_output, cuerpo_nom_fich, tit_graficos,dir_out_mc, hora_log) \n",
    "    \n",
    "    mensajes_log(tipo='MSG', texto=\"Memoria DESPUES MC: \" + str(get_mem()),nivel=5)\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_test, y_estimada, labels=[0,1])\n",
    "    tn, fp, fn, tp = cnf_matrix.ravel()\n",
    "                \n",
    "    tasa_fp = (int(fp) / (int(fp) + int(tn)))\n",
    "    \n",
    "    #### Estructura JSON    \n",
    "    dic_met = {\"config\": {\"algoritmo\": algoritmo, \"dataset\": usar_features, \"lab\" : tipo_lab, \"experimento\" : experimento, \"k\": k, \"iteracion\": iteracion, \"log\" : \"LOG_\"+hora_log, \"test\" : test}}\n",
    "    dic_met.update({\"formas\": {\"x_train\": X_train.shape, \"x_test\": X_test.shape, \"y_train\": y_train.shape, \"y_test\": y_test.shape}})\n",
    "    dic_met.update({\"matriz_confusion\" : {'tn': int(tn), 'fp' : int(fp), 'fn' : int(fn), 'tp': int(tp)}})\n",
    "    dic_met.update({\"class_report\" : clasif_repo})\n",
    "    dic_met.update({\"metricas_ad\": {\"rocc\": roc_score, \"kappa\": cohen_kappa_score(y_test, y_estimada)}})\n",
    "    dic_met.update({\"tiempo\": {\"tiempo_ejecucion\": str(t_ejecucion)}})\n",
    "    dic_met.update({'tasa_fp' : tasa_fp})\n",
    "                   \n",
    "    #Exportamos las métricas a fichero.\n",
    "    mensajes_log(tipo=\"EME\", f_dict=dic_met, texto=json.dumps(dic_met))\n",
    "    exportar_metricas_totales(file_metrics, dic_met)\n",
    "\n",
    "    #LOG y traza\n",
    "    mensajes_log(tipo='MSG', texto=\"Memoria FINAL metrica: \" + str(get_mem()),nivel=5)\n",
    "    mensajes_log(tipo='FME', hora_inicio=inicio_metrica, hora_fin=datetime.datetime.now(), texto=algoritmo, k=k, nivel=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_estimada, dir_output, cuerpo_nom_fich, tit_graficos, dir_out_roc, hora_log):\n",
    "    \n",
    "    valores_y = list(Counter(y_test).keys())\n",
    "    \n",
    "    # Binarizamos las salidas. En caso de solo haber 2 clases, devuelve 1 sola clase 0/1\n",
    "    y_test_bin = label_binarize(y_test, classes=valores_y)\n",
    "    y_est_bin = label_binarize(y_estimada, classes=valores_y)\n",
    "\n",
    "    #Calculamos la curva ROC y su area para cada clase\n",
    "    n_classes = y_test_bin.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    \n",
    "    for i in range(n_classes):\n",
    "       \n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_est_bin[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), y_est_bin.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    \n",
    "    #Grafico de la curva ROC multiclase\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "             label='micro-average ROC curve (area = {0:0.2f})'\n",
    "                   ''.format(roc_auc[\"micro\"]))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label='Curva ROC - clase {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "    roc_score = roc_auc_score(y_test_bin, y_est_bin)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa Falsos Positivos')\n",
    "    plt.ylabel('Tasa Verdaderos positivos')\n",
    "    \n",
    "    plt.title('Curva ROC (AUC={0:0.2f}) {1}'.format(roc_score, tit_graficos)) \n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    #Guardamos copia en la propia carpeta de log, a modo de backup\n",
    "    nombre_fichero = 'ROC_' + cuerpo_nom_fich\n",
    "    ruta_fichero_flog = dir_output + nombre_fichero + \".jpg\"\n",
    "    plt.savefig(ruta_fichero_flog, bbox_inches='tight')\n",
    "    \n",
    "    #Guardamos copia en el directorio de metricas\n",
    "    ruta_fichero_met = dir_out_roc + nombre_fichero + \".jpg\"\n",
    "    existe_f = comprobar_existe_fichero(ruta_fichero_met, hora_log, nivel=5)\n",
    "    plt.savefig(ruta_fichero_met, bbox_inches='tight')\n",
    "\n",
    "    plt.close(2)\n",
    "    \n",
    "    #LOG y traza\n",
    "    mensajes_log(tipo='MSG', texto=\"impreso grafico ROC \" + ruta_fichero_flog, nivel=5)\n",
    "    \n",
    "    return roc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_algoritmo(x_train, x_test, y_train, y_test, t_algoritmo, k, iteracion,mw_etiq_val,cuerpo_nom_fich,tit_graficos):\n",
    "    \n",
    "    #LOG y traza\n",
    "    inicio_algoritmo = datetime.datetime.now()\n",
    "    mensajes_log(tipo='IAL', hora_inicio=inicio_algoritmo, texto=t_algoritmo, nivel=4)\n",
    "    nombre_algoritmo=''\n",
    "    y_estimada=[]\n",
    "    file_pkl_export = dir_out_mod + 'fit_' + cuerpo_nom_fich + '.pkl'\n",
    "    file_test_export = dir_out_res + 'y_est_' + cuerpo_nom_fich\n",
    "    \n",
    "    print('shape of x_test algoritmos:', x_test.shape)\n",
    "    \n",
    "    if t_algoritmo == 'RL': #Regresion logistica\n",
    "        \n",
    "        nombre_algoritmo=\"REG. LOG.\"\n",
    "        LR = LogisticRegression().fit(x_train,y_train)\n",
    "        existe_f = comprobar_existe_fichero(file_pkl_export, hora_log, nivel=4)\n",
    "        joblib.dump(LR, file_pkl_export) # Guardo el modelo\n",
    "        y_estimada = LR.predict(x_test)\n",
    "        \n",
    "    elif t_algoritmo == 'SVM': #SVM\n",
    "        nombre_algoritmo=\"SVM\"\n",
    "        mvs = svm.SVC().fit(x_train, y_train)\n",
    "        existe_f = comprobar_existe_fichero(file_pkl_export, hora_log, nivel=4)\n",
    "        joblib.dump(mvs, file_pkl_export) # Guardo el modelo\n",
    "        y_estimada = mvs.predict(x_test)\n",
    "        \n",
    "    elif t_algoritmo == 'RFO': #Random Forest\n",
    "        nombre_algoritmo=\"R. FOREST\"\n",
    "        RF = RandomForestClassifier().fit(x_train, y_train)\n",
    "        existe_f = comprobar_existe_fichero(file_pkl_export, hora_log, nivel=4)\n",
    "        joblib.dump(RF, file_pkl_export) # Guardo el modelo\n",
    "        \n",
    "        y_estimada = RF.predict(x_test)\n",
    "    \n",
    "    elif t_algoritmo == 'NBA': #Nayve Bayes\n",
    "               \n",
    "        nombre_algoritmo=\"N. BAYES MN\"\n",
    "        NB_M = MultinomialNB().fit(x_train, y_train)\n",
    "        existe_f = comprobar_existe_fichero(file_pkl_export, hora_log, nivel=4)\n",
    "        joblib.dump(NB_M, file_pkl_export) # Guardo el modelo\n",
    "        y_estimada = NB_M.predict(x_test)\n",
    "\n",
    "        \n",
    "    elif t_algoritmo == 'ARD': #Arboles decision\n",
    "        nombre_algoritmo=\"ARB. DEC.\"\n",
    "        arb = tree.DecisionTreeClassifier().fit(x_train, y_train)\n",
    "        existe_f = comprobar_existe_fichero(file_pkl_export, hora_log, nivel=4)\n",
    "        joblib.dump(arb, file_pkl_export) # Guardo el modelo\n",
    "        y_estimada = arb.predict(x_test)\n",
    "        \n",
    "    else:\n",
    "        print(\"ERROR. No existe el codigo: \" + t_algoritmo) #TO-DO Bayes, random forest e ID3\n",
    "\n",
    "    #EXPORTAR DATOS Y estimada vs Y test\n",
    "    df_result_test = pd.DataFrame(mw_etiq_val, columns=['ORDEN_APP','APP_HASH','FAMILY_MALWARE','Y_TARGET'])\n",
    "    df_result_test['Y_ESTIMADA'] = y_estimada\n",
    "    \n",
    "    existe_f = comprobar_existe_fichero(file_test_export, hora_log, nivel=4)\n",
    "    df_result_test.to_csv(file_test_export,index=False) \n",
    "    \n",
    "    #LOG y traza\n",
    "    ahora=datetime.datetime.now()\n",
    "    t_ejecucion = ahora-inicio_algoritmo\n",
    "    mensajes_log(tipo='MSG', texto=\"Memoria tras ejecucion algoritmo \"+ t_algoritmo +\": \" + str(get_mem()),nivel=4)\n",
    "    mensajes_log(tipo='FAL', hora_inicio=inicio_algoritmo, hora_fin=ahora, texto=nombre_algoritmo, nivel=4)\n",
    "\n",
    "    return y_estimada, t_ejecucion\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar_ejecuciones(k, iteracion, usar_features, tipo_lab, experimento, test):\n",
    "    \n",
    "    seguir = False\n",
    "    \n",
    "    if os.path.exists(file_metrics):\n",
    "        with open (file_metrics, 'r') as f_metrics:\n",
    "            metrics = json.load(f_metrics)\n",
    "            \n",
    "        for algoritmo in lista_algoritmos:\n",
    "            seguir = True\n",
    "            \n",
    "            for result in metrics:                \n",
    "                if result[\"config\"][\"algoritmo\"] == algoritmo:\n",
    "\n",
    "                    for result2 in metrics:\n",
    "                        if result2[\"config\"][\"algoritmo\"] == algoritmo and result2[\"config\"][\"k\"] == k and result2[\"config\"][\"dataset\"] == usar_features and result2[\"config\"][\"lab\"] == tipo_lab and result2[\"config\"][\"experimento\"] == experimento and result2[\"config\"][\"iteracion\"] == iteracion and result2[\"config\"][\"test\"] == test:\n",
    "\n",
    "                            seguir = False\n",
    "                            break\n",
    " \n",
    "                    if seguir == True:\n",
    "                        break\n",
    "            if seguir == True:\n",
    "                break\n",
    "    else:\n",
    "        seguir = True\n",
    "   \n",
    "                \n",
    "    return seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprobar_ejecucion_algoritmo(algoritmo, k, iteracion, usar_features, tipo_lab, experimento, test):\n",
    "    seguir = True\n",
    "    \n",
    "    if os.path.exists(file_metrics):\n",
    "        with open (file_metrics, 'r') as f_metrics:\n",
    "            metrics = json.load(f_metrics)\n",
    "\n",
    "        for result2 in metrics:\n",
    "            if result2[\"config\"][\"algoritmo\"] == algoritmo and result2[\"config\"][\"k\"] == k and result2[\"config\"][\"dataset\"] == usar_features and result2[\"config\"][\"lab\"] == tipo_lab and result2[\"config\"][\"experimento\"] == experimento and result2[\"config\"][\"iteracion\"] == iteracion and result2[\"config\"][\"test\"] == test:\n",
    "\n",
    "                seguir = False\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                seguir = True\n",
    "                \n",
    "\n",
    "    return seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_train_test(iteracion, k_actual, df_etiquetas_train, df_etiquetas_test,df_dataset_train, df_dataset_test):\n",
    "    \n",
    "    malware_train = df_etiquetas_train.Y_TARGED.to_list()\n",
    "    malware_test = df_etiquetas_test.Y_TARGED.to_list()\n",
    "    \n",
    "    y_train = np.array(malware_train)\n",
    "    y_test = np.array(malware_test)\n",
    "    \n",
    "    \n",
    "    x_train = df_dataset_train.values\n",
    "    x_test = df_dataset_test.values\n",
    "\n",
    "    mw_etiq_val = df_etiquetas_test.values\n",
    "\n",
    "    for algoritmo in lista_algoritmos:\n",
    "        ejecutar = comprobar_ejecucion_algoritmo(algoritmo, k_actual, iteracion, usar_features, tipo_lab, experimento, test)\n",
    "\n",
    "        if ejecutar:\n",
    "            cuerpo_nom_fich = usar_features + '_' + algoritmo + '_L' + str(tipo_lab) + '_E' + str(experimento) + '_K' + str(k_actual) + '_I' + str(iteracion) +'_T' + str(test)\n",
    "            tit_graficos = algoritmo + ' ' + 'DS='+ usar_features + ' L=' + str(tipo_lab) + ' E=' + str(experimento) + ' K=' + str(k_actual) + ' I=' + str(iteracion)\n",
    "\n",
    "            y_estimada, t_ejecucion = ejecutar_algoritmo(x_train, x_test, y_train, y_test, algoritmo, k_actual, iteracion, mw_etiq_val,cuerpo_nom_fich,tit_graficos)\n",
    "\n",
    "            #Generamos las métricas e imprimimos la matriz de confusión y la curva ROC\n",
    "            generar_metricas(t_ejecucion, x_train, x_test, y_train, y_test, y_estimada, test, algoritmo, k_actual, iteracion, dir_output,usar_features,tipo_lab, experimento,hora_log,cuerpo_nom_fich,tit_graficos,dir_out_mc, dir_out_roc)\n",
    "\n",
    "        else:\n",
    "            mensajes_log(tipo='MSG',texto=\"Ya existe una ejecucion. Algoritmo: \" + algoritmo + \" K: \" + str(k_actual) + \" Iteracion: \" + str(iteracion) + \". Se suprime ejecucion.\",nivel=3)\n",
    "\n",
    "        mensajes_log(tipo='MSG',texto=\"Memoria tras algoritmos: \" + str(get_mem()))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprueba_directorios(IN_DATA,IN_TTV,OUT,RESULT,dir_output,dir_out_mod,dir_out_res,dir_out_metrics,dir_out_mc,dir_out_roc)\n",
    "\n",
    "iteraciones = [x for x in range(1,11)]\n",
    "\n",
    "for k_max in lista_k:\n",
    "\n",
    "    for iteracion in iteraciones:\n",
    "\n",
    "        #LOG y traza\n",
    "        inicio_ejecucion = datetime.datetime.now()\n",
    "        mensajes_log(tipo='INI', hora_inicio=inicio_ejecucion, texto=\"crear lista nombres APPs\")\n",
    "\n",
    "        list_dict_features_train=[]\n",
    "        list_dict_features_test=[]\n",
    "        lista_features=[]\n",
    "        lista_sum_features_app=[]\n",
    "\n",
    "        mensajes_log(tipo='MSG', texto=\"##########\")\n",
    "        mensajes_log(tipo='MSG', texto=\"########## COMIENZA ITERACION \"+ str(iteracion)+ \" - FEATURES: \" + usar_features + \" - LAB: \" + str(tipo_lab) + \" ##########\")\n",
    "        mensajes_log(tipo='MSG', texto=\"##########\")\n",
    "        mensajes_log(tipo='MSG', texto=\"Memoria inicial: \" + str(get_mem()), nivel=2)\n",
    "\n",
    "        ##lista_app = get_nombres_muestras(dir_features)\n",
    "\n",
    "\n",
    "        ### COMPROBAR SI QUEDAN EJECUCIONES PENDIENTES EN ESTA ITERACIÓN ###\n",
    "        ejecutar = comprobar_ejecuciones(k_max, iteracion, usar_features, tipo_lab, experimento, test)\n",
    "        ###\n",
    "        if ejecutar:\n",
    "            dir_logs_chi2 = IN_CHI + 'lab' + str(tipo_lab) + delimiter + 'exp' + str(experimento) + delimiter\n",
    "\n",
    "            nombre_fichero_chi = dir_logs_chi2 + 'chi2_' + usar_features + '_L' + str(tipo_lab) + '_E' + str(experimento) + '_I' + str(iteracion) +'_T' + str(test)\n",
    "            nombre_fichero_chi_apks_train = nombre_fichero_chi + \"_list_apks_TRAIN\"\n",
    "            nombre_fichero_chi_apks_test = nombre_fichero_chi + \"_list_apks_TEST\"\n",
    "\n",
    "            #LEER fichero CHI\n",
    "\n",
    "            df_chi = pd.read_csv(nombre_fichero_chi, sep='¬', engine='python', encoding='windows-1254')\n",
    "            \n",
    "            #CONTROL en caso de que no haya suficientes features\n",
    "            if df_chi['FEATURE'].count() < k_max:\n",
    "                print (\"El número total de features disponibles es menor que el seleccionado para ejecutar el modelo. NO se puede continuar con la ejecución.\")\n",
    "                break\n",
    "                \n",
    "            df_chi = df_chi.sort_values(['SCORE'], ascending=False, ignore_index=True)\n",
    "\n",
    "            lista_features = df_chi.loc[:k_max-1, 'FEATURE'].to_list()\n",
    "\n",
    "\n",
    "            \n",
    "            #La carga del listado daba problemas con read_csv por lo que se realiza leyendo linea a linea el fichero\n",
    "\n",
    "            #Cargar listado apks train\n",
    "            lista_app_train=[]\n",
    "\n",
    "            with open(nombre_fichero_chi_apks_train) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                line_count = 0\n",
    "                for row in csv_reader:\n",
    "                    if line_count > 0:\n",
    "                        lista_app_train.append([int(row[0]),row[1]])\n",
    "                    line_count += 1\n",
    "\n",
    "\n",
    "            #Cargar listado apks test\n",
    "            lista_app_test=[]\n",
    "\n",
    "            print (nombre_fichero_chi_apks_test)\n",
    "            with open(nombre_fichero_chi_apks_test) as csv_file:\n",
    "                csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "                line_count = 0\n",
    "                for row in csv_reader:\n",
    "                    if line_count > 0:\n",
    "                        lista_app_test.append([int(row[0]),row[1]])\n",
    "                    line_count += 1\n",
    "\n",
    "\n",
    "            del df_chi\n",
    "            gc.collect()\n",
    "\n",
    "            #LOG y traza\n",
    "            mensajes_log(tipo='FIN', hora_inicio=inicio_ejecucion, hora_fin=datetime.datetime.now(), texto=\"crear lista nombres APPs\")\n",
    "\n",
    "            ## EXTRAER FEATURES\n",
    "\n",
    "            #LOG y traza\n",
    "            inicio_ext_features = datetime.datetime.now()\n",
    "            mensajes_log(tipo='INI', hora_inicio=inicio_ext_features, texto=\"extraer features\")\n",
    "\n",
    "            #Crear cola para multiproceso con las muestras de train\n",
    "            cola_app_train = queue.Queue()\n",
    "            cola_app_train.queue = queue.deque(lista_app_train)\n",
    "\n",
    "            #Crear cola para multiproceso con las muestras de test\n",
    "            cola_app_test = queue.Queue()\n",
    "            cola_app_test.queue = queue.deque(lista_app_test)\n",
    "\n",
    "            #llamada a extraer_features conjunto train\n",
    "            procesar_extraer_features(cola_app_train, list_dict_features_train,dir_features) \n",
    "\n",
    "            #llamada a extraer_features conjunto test\n",
    "            procesar_extraer_features(cola_app_test, list_dict_features_test,dir_features)\n",
    "\n",
    "            #Creamos un array de \"num_apps\" como filas y \"num_features\" como columnas. Rellenamos con 0 todas las posiciones\n",
    "            array_ceros_train = np.zeros((len(lista_app_train), len(lista_features)), dtype=np.uint8)\n",
    "            array_ceros_test = np.zeros((len(lista_app_test), len(lista_features)), dtype=np.uint8)\n",
    "\n",
    "            df_dataset_train = pd.DataFrame(array_ceros_train, columns=lista_features)\n",
    "            df_dataset_test = pd.DataFrame(array_ceros_test, columns=lista_features)\n",
    "\n",
    "            ## RELLENAR DATASET\n",
    "\n",
    "            #LOG y traza\n",
    "            inicio_rellenar = datetime.datetime.now()\n",
    "            mensajes_log(tipo='INI', hora_inicio=inicio_rellenar, texto=\"rellenar dataset\")\n",
    "\n",
    "            #Crear cola para multiproceso con las features de test\n",
    "            cola_features_train = queue.Queue()\n",
    "            cola_features_train.queue = queue.deque(list_dict_features_train)\n",
    "\n",
    "            #Crear cola para multiproceso con las features de train\n",
    "            cola_features_test = queue.Queue()\n",
    "            cola_features_test.queue = queue.deque(list_dict_features_test)\n",
    "\n",
    "            procesar_rellenar_dataset(cola_features_train, df_dataset_train)\n",
    "            procesar_rellenar_dataset(cola_features_test, df_dataset_test)\n",
    "\n",
    "            #LOG y traza\n",
    "            mensajes_log(tipo='FIN', hora_inicio=inicio_rellenar, hora_fin=datetime.datetime.now(), texto=\"rellenar dataset\")\n",
    "\n",
    "            #TRAZA RESUMEN PARTE INICIAL\n",
    "            fin_ejecucion = datetime.datetime.now()\n",
    "            mensajes_log(tipo='RES', hora_inicio=inicio_ejecucion, hora_fin=fin_ejecucion, texto=\"carga inicial DATASET\")\n",
    "\n",
    "            #Calculamos el descuadre de features adquiridas de los ficheros vs los 1 de la fila correspondiente a cada app\n",
    "            #if calcular_descuadre==1:\n",
    "            #    print ('DESCUADRE: ' + str(comprobar_integridad(df_dataset)))\n",
    "\n",
    "            ## EXTRACCION DE ETIQUETAS\n",
    "            #LOG y traza\n",
    "            inicio_etiquetado = datetime.datetime.now()\n",
    "            mensajes_log(tipo='INI', hora_inicio=inicio_etiquetado, texto=\"etiquetado\")\n",
    "\n",
    "            ##El etiquetado, en la actualidad podría cogerse al cargarse las muestras de cada iteración,\n",
    "            ##pero estos cambios fueron posteriores. TRABAJO FUTURO\n",
    "            df_etiquetas_train, estado = crear_etiquetado(dir_malware, lista_app_train, tipo_lab, dir_dict_fam)\n",
    "            df_etiquetas_test, estado2 = crear_etiquetado(dir_malware, lista_app_test, tipo_lab, dir_dict_fam)\n",
    "\n",
    "            ### Control de cara a actualización en trabajo futuro ###\n",
    "            #if estado == False or estado2 == False:\n",
    "                #print (\"Numero de familias superior al permitido (255). Se finaliza la ejecución.\")\n",
    "                #mensajes_log(tipo='MSG', texto=\"Numero de familias superior al permitido (255). Se finaliza la ejecucion.\")\n",
    "                #sys.exit\n",
    "\n",
    "            #LOG y traza\n",
    "            mensajes_log(tipo='FIN', hora_inicio=inicio_etiquetado, hora_fin=datetime.datetime.now(), texto=\"etiquetado\")\n",
    "\n",
    "            ejecutar_train_test(iteracion, k_max, df_etiquetas_train, df_etiquetas_test,df_dataset_train, df_dataset_test)\n",
    "\n",
    "            ##Limpiar memoria\n",
    "            del df_dataset_train, df_dataset_test, df_etiquetas_train, df_etiquetas_test\n",
    "            gc.collect()\n",
    "\n",
    "        else:\n",
    "            mensajes_log(tipo='MSG',texto=\"Iteracion ya completada en otra ejecución.\",nivel=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
